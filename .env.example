# OMI-to-Notion Semantic Intelligence Layer
# Environment Configuration Template
# Copy this file to .env and fill in your values

# =============================================================================
# OMI Configuration
# =============================================================================
# Your OMI API key (obtain from OMI dashboard -> Settings -> API Keys)
OMI_API_KEY=your_omi_api_key_here

# OMI API base URL
OMI_API_URL=https://api.omi.me/v1

# Webhook secret for verifying incoming webhook requests (optional)
OMI_WEBHOOK_SECRET=your_webhook_secret_here

# =============================================================================
# Notion Configuration
# =============================================================================
# Notion integration token (from https://www.notion.so/my-integrations)
NOTION_API_KEY=secret_your_notion_integration_token

# Notion database ID (from database URL: notion.so/workspace/{database_id}?v=...)
NOTION_DATABASE_ID=your_database_id_here

# Notion API version
NOTION_VERSION=2022-06-28

# =============================================================================
# Processing Configuration
# =============================================================================
# Minimum relevance score (0.0-10.0) for syncing to Notion
MIN_RELEVANCE_SCORE=5.0

# Minimum confidence threshold (0.0-1.0) for classifications
MIN_CONFIDENCE_THRESHOLD=0.65

# Number of transcripts to process in a batch
BATCH_SIZE=10

# Processing mode: 'realtime' for webhook-based, 'batch' for scheduled
PROCESSING_MODE=realtime

# Maximum transcript length (characters) to process
MAX_TRANSCRIPT_LENGTH=50000

# =============================================================================
# AI/ML Services (Optional)
# =============================================================================
# OpenAI API key for advanced NLP features
OPENAI_API_KEY=your_openai_key_here

# HuggingFace token for downloading models
HUGGINGFACE_TOKEN=your_hf_token_here

# Use local models instead of API-based models (true/false)
USE_LOCAL_MODELS=true

# SpaCy model to use for NLP
SPACY_MODEL=en_core_web_lg

# =============================================================================
# Server Configuration (for real-time mode)
# =============================================================================
# Host to bind the webhook server
SERVER_HOST=0.0.0.0

# Port for the webhook server
SERVER_PORT=8000

# =============================================================================
# Logging Configuration
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Directory for log files
LOG_DIR=./logs

# Enable JSON formatted logs (true/false)
LOG_JSON_FORMAT=false

# =============================================================================
# Environment
# =============================================================================
# Environment name: development, staging, production
ENVIRONMENT=development
